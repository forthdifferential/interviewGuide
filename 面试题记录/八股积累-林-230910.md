## C++

### const修饰的变量可以修改吗？

直接修改是不行，可以用指针取它的地址间接修改



### C语言如何实现面向对象？

封装--> struct 表示类，成员函数就自己定义一个this指针，传类对象的指针

继承--> struct里面包含父类

多态--> 写一个虚函数表类，要实现多态的类包含虚表类的指针，然后传不同的指针做不同的判断，调用虚表中的不同函数。



### 为什么条件变量和mutex要一起使用？

条件变量一般是表示状态，如果没有锁的加持，你对某个资源的状态判断可能是错误的。



### 什么时候用拷贝构造？什么时候用赋值？

拷贝构造是用一个已经构造好的对象去初始化一个新的对象，赋值是有两个构造好的对象，一个对象对另一个对象进行赋值。



### 什么时候用智能指针，什么时候用裸指针？

指针其实有四种（漏了一种auto_ptr），shared_ptr, weak_ptr, unique_ptr和裸指针，其中最常用的就是unique_ptr和裸指针，因为shared_ptr有引用计数，额外的开销比较大。一般写应用时，遇到指针我一般都是先无脑用unique_ptr，如果遇到需要一个副本，就改成shared_ptr，写完之后看哪些指针的生命周期是全局生命周期，最后再把它改成裸指针。说简单点，就是局部作用的地方用unique，多处作用用shared，全局用裸指针。



### weak_ptr什么时候使用

1、解决share_ptr循环引用的问题

2、当你想使用对象，但是并不想管理对象（没有拥有控制权），并且在需要使用对象时（lock）可以判断对象是否还存在（expired）。比如有个类只用观察某个变量的状态然后不同的状态做出不同的操作，但又不实际操控这个变量的资源，这时候就可以用weak_ptr。（观察者模式）



### Shared_ptr线程安全吗

Shared_ptr本身是线程安全的，它的引用次数加减操作内部自动实现加锁解锁。

但是用智能指针去访问资源不是线程安全的，需要手动加锁解锁。



### Shared_ptr的缺点

传播病毒（污染）：一旦对资源对象染上了shared_ptr，在其生存期内便无法摆脱。比如 **创建了一个shared_ptr p1，然后p2通过调用get接口获得到了对象资源，然后p3通过这个p2的裸指针也构造了一个shared_ptr，此时p1的计数器为1，p3的计数器也是1，当离开作用域时，p3计数器清零并释放资源，p1也会释放，这时候就再次释放，导致程序崩溃。**

然后就是开销大，维护计数器，还要维护计数器的线程安全，线程安全是通过原子量来实现的，但是还是有开销。



1. 线程不安全;
2. 管理资源能力单一：不能管理malloc出来的资源（可以添加删除器），不能管理文件指针；
3. 可能会产生循环引用的问题；



### vector会缩容吗

vector封装的一些接口是不会缩容的（resize也不行，有的编译器可以）。想要缩容，可以新建一个小的vector，然后swap。



### vector线程安全吗？Stl线程安全吗

外部使用不安全。得加锁。内部安全，比如shared_ptr的计数器。



### vector的clear的时间复杂度

O(N)



### 在C++中，多继承会导致类继承了多个基类，可能存在同名虚函数的情况，出现二义性。如何处理二义性？

只能显式调用，加类作用域



### vector的reserve和resize的区别

reserve只修改capacity大小，不修改size大小，resize既修改capacity大小，也修改size大小，会创建新的对象。



### 为什么是2或者1.5倍扩容

扩容的机制：开辟新空间，拷贝元素，释放旧空间。

而理想的方案是我在下一次扩容的时候，**如果刚好可以利用前n-1次所释放的空间，那就太好了。**

如果恰巧以2倍方式扩容，那么每次扩容时前面释放的空间它都不足以支持本次的扩容！



### 如何避免重复扩容

如果在插入之前，可以预估vector存储元素的个数，提前将底层容量开辟好即可。如果插入之前进行reserve，只要空间给足，则插入时不会扩容，如果没有reserve，则会**边插入边扩容，效率极其低下**。



### 萃取技术

当函数，类或者一些封装的通用算法中的某些部分会因为数据类型不同而导致处理或逻辑不同，traits会是一种很好的解决方案。

比如STL里面有几种不同的迭代器，然后函数模板传参进来使用时不知道是哪种类型的迭代器，然后就可以调用traits函数，来获取他们的类型，这个traits函数是提前写好的模板特化，主要是用typedef，然后可以获取不同的类型。



### 虚指针及虚表

虚表：里面维护了多个函数指针

虚表是怎么生成的：在编译的时候就定好了，为每个类生成的：先复制父类的虚函数表，然后替换已重写父类的虚函数指针，然后添加自己的虚函数指针。

每个类对象在构造时（因此构造函数里面不要调用虚函数），会生成一个虚指针，指向虚表。

如果子类继承了两个父类，两个父类都有虚函数，那么子类就有两个指针。



### 野指针和悬空指针的区别

“野指针”(wild pointer)：是没有被初始化过的指针，所以不确定指针具体指向。

“悬空指针”（dangling pointer）：是指针最初指向的内存已经被释放了的一种指针



### 哪些场景会内存泄漏

- 忘记delete了，或者没有delet数组
- 父类的析构函数不是虚函数
- 构造函数发生异常，没调用析构函数



### 内存泄漏如何排查

经验法就是：

- new delete有没有成对出现。
- 析构函数是不是虚函数



工具的话我只用过valgrind，它有很多参数。

```
valgrind -options ./proc args
```

常用的options，有trace-children跟踪子进程，当然最常用的就是memcheck选项，检查内存问题。它会打印若干类型，directly lost，indirectly lost，possible lost，still reachable。主要是directly和still reachable，前者的意思是有一个内存没有释放，并且所有指针变量都访问不到这块内存。后者表示可以访问，但是还没释放。



--leak-check 会显示具体位置



### Mutable使用场景

Mutable只能作用在类成员上，不能和const同时修饰一个成员。通常是使用方式是在const成员函数里修改Mutable的成员变量。



### 四种类型转换

static_cast：最常用的，可以用于内置类型的转换，父类子类的转换（向上是安全的，向下是不安全的（但是缺乏类型检查，所有要尽量避免））。

const_cast：用于去除const和valitale属性。

reinterpret_cast：最暴力的强制类型转换，不管两个类型是否相关都可以转换，但是原类型和目标类型必须要有一个是指针，可以把指针转换成整数，如果比特位数一样。

dynamic_cast：其他的都是在编译时处理，这个时在运行时处理的（有开销），运行时会进行类型检查，所有在有多态的场景下，在进行下行转换时更安全，因为这个特点，它只能作用于指针或者引用。



### 编写.h文件时需要注意的事

1、<>和引号的问题，系统自带的使用尖括号，引号一般是自己写的文件

2、pragma once，防止重复定义

3、模板的实现一般放在头文件里，因为编译的时候模板文件时并不会生成实例化代码，在链接阶段，在使用模板的地方会去实例化，这时候编译器就会去找头文件，这时候是感知不到.cpp文件的，如果不把源代码放在头文件里，就会编译失败。



### delete怎么知道释放多大

如果是普通的对象，则可以直接计算大小。

如果是数组，则C++在new的时候会额外分配四个字节的大小存数组的大小，delete 数组的时候读这个位置就可以了。



### C++ exception的底层原理

主要有三个关键字：throw try catch，catch是处理某些异常的特殊情况的。

当一个异常发生时，编译系统必须完成以下事情：

- 检验发生throw操作的函数
- 决定throw操作是否发生在try区段中
  - 如果是，编译系统必须把exception type拿来和每一个catch子句比较
  - 如果比较吻合，流程控制应该交给catch子句
- 如果throw的发生并不在try区段中，或者没有catch子句吻合，那么系统就必须：
  - 销毁所有的active local objects
  - 从堆栈中将当前的函数unwind掉
  - 进行到程序堆栈中的下一个函数中去，然后重复上面



### C的内存管理函数有哪些？

malloc函数：申请一块未被初始化的堆内存，可以用for/memset进行初始化

calloc函数：申请已被初始化的堆内存，例如int初始化为0，double初始化为0.000000

realloc函数：扩容函数，前提是已经动态申请内存空间，之后内存不够用，才能够进行扩充

1. 后续未分配内存空间足够大，可以分配空间。此时直接连续开辟空间
2. 后续未分配内存空间不足够大，不能分配空间。此时舍去原有的空间，在堆内重新寻找一块足够大的内存进行空间的开辟，将原有数据复制到新的空间
3. 堆内存不足，扩展空间失败

free函数：free用来释放从malloc、realloc、calloc成功获取到的动态内存分配的空间。



### 怎么实现malloc

malloc 函数的实质是它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表。 调用 malloc（）函数时，它沿着连接表寻找一个大到足以满足用户请求所需要的内存块。（如果没有搜索到，那么就会用sbrk()才推进brk指针来申请内存空间）。  然后，将该内存块一分为二（一块的大小与用户申请的大小相等，另一块的大小就是剩下来的字节）。 接下来，将分配给用户的那块内存存储区域传给用户，并将剩下的那块（如果有的话）返回到连接表上。 调用 free 函数时，它将用户释放的内存块连接到空闲链表上。





### static关键字的作用

1. 修饰全局变量和函数时，表明一个全局变量只对定义在同一文件中的变量函数可见。         
2. 修饰局部变量时，表明该变量的值不会因为函数终止而丢失。 
3. 修饰类的数据成员，表明对该类所有对象这个数据成员都只有一个实例。即该实例归 所有对象共有。
4. 静态成员函数只能访问它的参数、类的静态数据成员和全局变量。



### 如何限制对象只能在堆上创建

将析构函数设置为私有。编译器会检查析构函数的访问性。当析构函数设为私有时,编译器创建的对象就无法通过访问析构函数来释放对象的内存空间,因此,编译器不会在栈上为对象分配内存。



### 构造函数和析构函数能抛出异常吗？

构造函数可以抛出异常，但是不建议这么做。

析构函数不能、也不应该抛出异常。原因有两点：

- 如果析构函数抛出异常，则异常点之后的程序不会被执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会被执行，会造成诸如资源泄露的问题。
- 通常异常发生时，C++机制会调用已经构造对象的析构函数来释放资源，此时如析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。



### gcc怎么取消编译过程中的优化

在对应的代码段添加gcc的选项：GCC optimize("O0")



### C++怎么调用C

extern “C”{...}



### new的时候内存不够了怎么办

操作系统会对其他进程占用的内存做垃圾回收，或者把数据保存成镜像文件，然后腾出来给当前进程用。如果实在没有办法分配了，进程会抛出异常。其实操作系统给进程分配的都是虚拟内存，实际分配到物理内存的时候应该会有很多碎片，这里应该会有调整空间的。



### 构造函数，析构函数，虚函数

- 构造函数可以是虚函数吗？

  不行，因为虚函数的调用是需要虚指针的，而虚指针是构造函数里构造的，假如构造函数是虚函数，那么就没有构造好的虚指针给它调用了

- 构造函数可以调用虚函数吗？

  可以，但是起不到效果，类的构造次序是由父类到子类，假如构造一个子类，调用的时候是父类的虚指针指向的虚表起到作用。

- 析构函数可以是虚函数吗？

  最好是，一个父类指针指向子类对象，为了析构子类的空间，必须是析构的。

- 析构函数可以调用虚函数吗？

  可以，同样起不到效果，析构过程是从子类析构到父类，假如析构一个父类指针指向子类，调用时子类已经被析构了，调用时时父类指针指向的虚表起到作用。

  

### move是什么，使用场景，什么时候用move比不用快

move的作用主要是更改对象的所有权，将一个对象的所有权给另一个对象，使用起来就是传一个左值进来然后变成右值。

使用场景：

(1) 避免无意义的大规模拷贝 用移动
(2) 包含不可复制的数据 用移动

什么时候更快，比如现在有一个变量string A，然后我想要把它push_back进一个vector，这个时候用move更快，因为相当于是直接将这个已经构造好了的临时变量push到vector里面，如果不用move则会再多一层拷贝构造函数的调用。

实现：首先有一个接收万能引用的参数，然后将参数转换为右值引用 



### 右值引用的场景和好处

左值的短板：

- 左值引用做参数，能够完全避免传参时不必要的拷贝操作。
- **左值引用做返回值**，并不能完全避免函数返回对象时不必要的拷贝操作。（不能返回局部对象的引用）

场景1：右值引用为了解决这个痛点（返回局部对象时需要拷贝），就和移动构造函数一起诞生了，对于一个函数返回局部对象时，现代编译器，如果这个对象的类支持移动构造，那么他就会进行移动构造，这个就避免了一次拷贝，增加了效率。

场景2：比如现在有一个变量string A，然后我想要把它push_back进一个vector，这个时候用move更快，因为相当于是直接将这个已经构造好了的临时变量push到vector里面，如果不用move则会再多一层拷贝构造函数的调用。



### 引用折叠

一般用于模板。形参是T&&（完美转发的一种） ，传左值是左值，传右值是右值。（只要有一个左值就是左值）。

另一种完美转发：std::forwad\<T\>()，解决的是想要将参数传给另一个函数，并且保留左右值的属性。



### const 值不构成函数签名，const 指针和const *会构成函数签名



### const 成员函数会构成函数签名



### 工厂模式场景

某个类的创建逻辑比较复杂，比如很多if else判断或者要new很多东西，这个时候可以全部写在工厂类中。用不用的时候，一般是考虑创建这个过程到底能不能**对创建者透明**，如果允许透明，就可以用。（代码复用、解耦作用）



### new的过程

- 通过operator new申请内存
  - 本质上也是调用malloc申请内存，malloc申请内存小于128K时，使用brk系统调用在堆区申请内存，堆区的指针移动。大于128K时，使用mmap系统调用在文件映射区（栈区和堆区之间）中分配。
- 使用placement new调用构造函数（简单类型忽略此步）
- 返回内存指针

<img src="./process_data.png" width="50%">



### 快排如何优化

首先：快排的循环里面没有等于号

快速排序的运行时间与划分是否对称有关。最坏情况下，每次划分过程产生两个区域分别包含n-1个元素和1个元素，其时间复杂度会达到O(n^2)。

基准选择，取中最快。

优化：

1：序列长度达到一定大小时，使用插入排序

2：尾递归优化

如果一个函数中所有递归形式的调用都出现在函数的末尾，当递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分时，这个递归调用就是尾递归。当编译器检测到一个函数调用是尾递归的时候，它就覆盖当前的活动记录而不是在栈中去创建一个新的，**通过覆盖当前的栈帧而不是在其之上重新添加一个，这样所使用的栈空间就大大缩减了**，这使得实际的运行效率会变得更高。

3：聚集元素

在一次分割结束后，将与本次基准相等的元素聚集在一起，再分割时，不再对聚集过的元素进行分割。

4：多线程处理快排



### 内存对齐的好处

假如cpu一次只能读四个字节，假如一块数据为234|5，那么就需要读两次。所以，内存对齐可以有效地提高CPU读写内存的速度，但是浪费一点空间。



### protected

子类对象可以访问父类对象的protected成员



### 内联函数

作用：快，避免调用，编译时直接替换。缺点：程序变大

构造函数、析构函数即使写了也不会内联，因为编译器会做额外补充，就认为它不够精简。

虚函数不能内联，因为内联是静态的。



### 智能指针一定能避免内存泄漏吗

循环引用。或者直接使用了它get的裸指针。



### 类的成员变量可以是引用吗

可以。但是必须在初始化列表中初始化。



### override表示函数应当重写基类中的虚函数(用于派生类的虚函数中)



### C++ 和 C 编译的区别

C++编译器可以编译C代码，反过来不行。因为C++语法更加严格，并且有更多的特性，会做更多的判断。比如函数重载，函数类型检查，多态，模板的一些方法，C代码检查不了。



### extern

如果文件b.c需要引用a.c中变量int a，就可以在b.c中声明extern int a，然后就可以引用变量a。

extern的原理很简单，就是告诉编译器：“你现在编译的文件中，有一个标识符虽然没有在本文件中定义，但是它是在别的文件中定义的全局变量，你要放行！”

通常起声明作用，不要拿它定义。(声明可以多次，定义只能一次)

```c++
extern int a = 10;//尽量不要写这种定义方式
int a = 10;//上述两条语句等价
```



### 项目中怎么使用多态的

Object和光线（三角片）求交，object可以是三角片，可以是球，可以是model。

还有一些简单的矩阵运算用了模板。



### std::future 和 std::packged_task

​		我们想要从线程中返回异步任务结果，一般需要依靠**全局变量**；从安全角度看，有些不妥；为此C++11提供了std::future类模板，**future对象提供访问异步操作结果的机制**，很轻松解决从异步任务中返回结果。

​		简单来说std::packaged_task\<F>是对可调对象(如函数、lambda表达式等)进行了包装，并将这一可调对象的返回结果传递给关联的std::future对象。

```c++
#include<functional>
#include<future>
#include<thread>
#include<iostream>

int test(int a)
{
    a+=10;
    return a;
}

int main()
{
    std::packaged_task<int(int)> fun1(test);
    std::future<int> res=fun1.get_future();
    
    std::thread t1(fun1,100);//切记：传入线程中的是pack打包好的函数。而不是上面那个。
    
    std::cout<<res.get()<<std::endl;
    return 0;
    
}
```





### 哈希冲突的优劣

拉链：插入方便，动态，删除容易。但链表太长速度也会退化。——一般用于想要动态扩容

开放寻址：只要有位置就一定能插入。但空间是固定的，寻址次数不可控，删除加墓碑也麻烦。——一般用于空间充足

再哈希：计算次数可能变多。



### 红黑树性质

性质1：每个节点要么是黑色，要么是红色。

性质2：根节点是黑色。

性质3：每个叶子节点（NIL）是黑色。

性质4：每个红色结点的两个子结点一定都是黑色。

**性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。**



### new和malloc失败会怎么样

new会抛出bad_alloc异常，malloc返回null



### new和free混用

如果在使用 new 分配内存之后，使用 free 释放，就会造成内存泄漏。因为new对应的delete还会调用析构函数，假如一个指针指向的对象在构造函数里申请了资源，那么因为没有调用析构函数就会内存泄漏。free本质上是看类的大小释放内存的，类里面的指针可能还指向有内存资源。



### unique_ptr是支持move构造的，unique_ptr对象可以被函数返回。



### 排序稳定性问题

冒泡，插入排序稳定，归并排序稳定

堆排序、快排、希尔排序不稳定





### 全局变量啥时候构造，有顺序吗

进入main函数之前构造，没有顺序，避免相互依赖。



### 一个函数f(int a, int b)的b和a的地址关系？

b先存入栈中，在a高4个字节的位置。



### 按引用捕获时需要注意引用的变量生命周期和lambda被使用的生命周期





### 哪个关键字可以让程序在编译阶段进行计算?

constexpr



### 静态链接和动态链接的区别和优点

静态链接的过程就已经把要链接的内容已经链接到了生成的可执行文件中，就算你在去把静态库删除也不会影响可执行程序的执行；

而动态链接这个过程却没有把内容链接进去，而是在执行的过程中，再去找要链接的内容，生成的可执行文件中并没有要链接的内容，所以当你删除动态库时，可执行程序就不能运行。

1、静态链接库执行速度比动态链接库快。（执行过程不需要找链接的内容）
2、动态链接库更节省内存。（未写入要链接的内容）
3、动态链接生成的可执行文件要比静态链接生成的文件要小一些。



### 改变动态链接库中的哪一部分代码会导致重新编译?（使用库的程序）

只要不修改动态库的名字和动态库导出的供可执行文件使用的函数（名字，返回值，参数），就不需要重新编译，编译好新的动态库后只需要简单的替换原有动态库，下一次运行程序时就可以使用新的动态库了。 



### rand()函数写法

并不是随机的。使用的前面还需要使用srand(time(0))



### 工作同事不配合怎么办？

1、先说为什么需要他，说明这个活儿的背景和需求，为什么需要他，而不是说随便拉个人干杂活

2、然后说这个活儿对咱俩都有好处，可以看看KPI考核内容之类的，具体找找有啥好处

3、实在不干的话，可以用领导的名号压他，尽量还是不麻烦领导，实在不行就只有找领导沟通了。

4、干完就要感谢，分享荣誉。



---

## 数据库

### B树，B+树，红黑树，跳表的应用场景

红黑树 VS 跳表：如果单纯比较性能，跳表和红黑树可以说相差不大，并发情况下跳表好，比如插入一个节点，因为红黑树涉及到rebalance，要锁的东西比较多，而跳表需要更新的东西更少。但跳表的缺点是内存占用比较大，因为有很多层，**有大量重复的节点**。红黑树和跳表本质上都是有序的，leveldb中memtable理论上来说其实也可以用红黑树实现，只要是有序的就可以。

红黑树 VS B+树：他们也都是有序的。红黑树属于二叉树的一种，因为是二叉树，所以当数据量大时，树就比较高，所以就不适合IO级别的操作，更适用内存级别的操作，因为树高在查找时就会查多次，IO操作代价太大了。B+树因为高度更低，一个节点可以有多个儿子，所以广泛用于数据库。

红黑树 VS AVL树：红黑树和AVL树都是高效的平衡二叉树，增删改查的时间复杂度都O(logN)，红黑树不追求绝对平衡，其只需保证最长路径不超过最短路径的2倍，相对而言，降低了插入和旋转的次数，所以在经常进行增删的结构中性能比AVL树更优，而且红黑树实现比较简单，所以实际运用中红黑树更多。

B+树 VS 跳表：B+树是多叉树，所以层数比较低，Mysql中一个B+树的节点可以放16k的数据，三层左右就可以存储2kw条数据。而跳表的话，如果想要达到二分的效果，2的24次方大概等于2kw，需要24层，那么查一条数据需要24次磁盘IO，所以对于数据库这种数据基本都存在磁盘上的场景是不可以接受的。但跳表的插入性能会好一些，没有b+树维持平衡的开销，且并发读写性能会好一些。



### B+树每一层越宽越好吗

如果是极端情况子节点个数就等于总个数，那么B+树退化成了线性表数组，检索效率大大下降，这种情况肯定是不行的。



### LSM

B+树利用叶子节点形成的链表有较好的顺序读写能力，但**随机读写性能不佳**，严重依赖磁盘的随机读写能力，**尤其是写，还涉及到B+节点的合并和分裂**。

但在写密集场景，这种不好的写性能是不可接受的，因此想要一种写性能好一点的结构，所以提出了LSM，**通过追加写，牺牲读性能提高写性能，通常应用于写密集场景比如日志**。

因为是追加，多了两个问题：

- 一个是一个kv现在有了多份数据，**浪费了空间**，需要GC（在compaction时完成，旧的kv会被抛弃）；

  因为GC，所以所有的数据不能是一个流式文件，因为一边对一个文件GC，这个文件又在不断添加数据，分界就不好做，干脆就把文件分成多个，对那些已经固定不变的文件进行GC，提出**文件分段思想**。

- 另一个是假如想读一个比较旧的数据，就要去翻找很久很久之前的记录，**读性能就显著下降**了，所以怎么优化这个问题？

  首先，为了**支持范围查询**，提出了排序，保证每个文件是有序的。

  > 最核心的思想！
  >
  > 但是不同文件中，可能有相同的key，读一个key就需要遍历所有的文件，所以就提出了压缩，利用**归并**排序，**保证每个文件的key不重叠**，这样就只用读某些特定的文件。**因为除了第0层的文件，其他层的文件的key不重叠，所以0以上层的文件，每层只用读一个，大大提高的读性能。**为什么0以上层的文件key不重叠，因为合并的时候是将上一层的文件和当前层文件有重叠的文件进行合并的，每次合并出来就是不重叠的。
  >
  > 那**leveldb为什么要分层呢？为了分摊写放大（写一次要做很多操作）。**假如只有一层，在一个新的memtable来的时候，这个memtable的数据范围特别广，为了保证每个文件key不重叠，那么它就要和一层里面的所有文件进行归并，这样的代价太大了，会导致系统在那个时间段卡顿，因此采用分层的结构，限制了每一层的大小，这样当一个新的memtable到来时，一层内的归并的数量就会少一些，当该层满了才推到下层，也就是说把一下子大量的合并分时间段进行，提高了系统的瞬时响应速度。

  **为了每次读不是到磁盘里面读，就在内存中维护了一个memtable，这个是有序的，优先在内存中查数据**。因为内存空间是有限的，所以memtable大小达到一定规模时，就需要dump到磁盘上，但又不能memtable一边接受数据一边dump，所以就有一个imumemetable，memtable满了就变成imumemetable，然后新开一个空的memtable接收数据。

**如何compaction？**

- minor compaction：memtable满了，转换成immutable memtable，然后落盘。
- major compaction：某一层满了，则通过round robin的方式选一个文件，然后和下一层的所有文件使用多路归并的方式进行合并。（level0 可能得选多个，因为有重叠）；某个文件seek的miss次数太多，也需要合并。



优化方向：提高读性能和空间利用率

调参：层数，文件大小，布隆过滤器大小，合并策略

优化读写放大及合并压缩：kv分离，跳跃合并（假如知道一个文件和12层没有重叠，就直接拿到第3层合并），冷热分离（热数据尽可能留在内存中），并行IO调度

新硬件：SSD



KV分离：SSD用的是二极管不是磁头，他的随机读写性能和顺序读写性能几乎一样。但是他有擦写次数的限制，因为LSM结构有写放大，所以LSM写放大会缩短SSD的寿命；LSM无法发挥SSD并行读写的特性。

KV分离主要针对的是大value的写入，SStable中不存放value值，而存的是指针。1这样在合并时，不用频繁地移动value值，写放大就减少；2一个文件中可以存放更多的kv，Memtable也可以存放更多的kv，缓存更多数据，间接降低了读放大。

但存指针的方式，就需要“回表”，顺序读写会变成随机读写，这时候就可以利用SSD好的随机读特性，并且可以一次性累计多个位置信息，并行SSD读写特性去并行地进行读写。



### mysql怎么解决幻读的？彻底解决了吗？

首先这里讨论的隔离级别是Repeatable Read; mysql读有两种，一种是快照读，一个是当前读；

普通的select语句往往是**快照读**，它是通过**mvcc**读版本链去读数据的，**因为readview的存在，幻读得到了减少**，但也没彻底解决，在Repeatable生成Readview时，是在事务开始时产生的并且只有这一个，理论上来说整个事务是只用这一个Readview来检查数据的可读性的，在读版本链时是不会读新版本的数据的，但是有一种情况就是，假如事务**A刚开始select时并未发现**这个数据，另一个事务**B插入了一个数据**，然后事务A去**update**这个数据，因为**update是当前读**，所以此时会读到最新的数据，然后A**再select**，是会select到的，这就发生了幻读。

另一种是当前读，当前读就是想要读最新的数据，比如select ... for update或者insert等语句，这种时候就需要对最新的数据加锁之后再读，mysql是通过行锁加**间隙锁**来减少幻读的，但是在该隔离级别下并未彻底解决，如果**事务开启后**，并没有执行当前读，而是**先快照读**，然后这期间如果其他事务插入了一条记录，那么事务**后续使用当前读**进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。

总结一下，就是在一个事务中，**当前读和快照读混用**，就可能发生幻读。



### sql慢了怎么查？

1先去打开mysql的**慢查询日志**，看是哪个耗时最长；

2用explain去看sql有没有命中索引，看耗时最长的那个对应的表，有没有索引，索引是否合理，并检查自己的语句是否合理，有没有符合最左匹配

- 重点关注哪些列？
- type：本次查询的方式，如null，index，range；
- key：选择的哪个索引；
- rows：扫描多少记录，越小越好

3看单表是否数据量过大，单表数据过大，有会导致查询瓶颈，这个情况就应该切分表

4网络原因

5如果是写表的话，也有可能是bufferpool刷脏页到磁盘比较慢



### 哈希表避免冲突

开放寻址，冲突了就找下一个位置，有空就插入

链表，就挂在链表末尾

再次hash



### 什么时候适合创建索引

经常出现在where语句里面的列最好创建。经常Group by 或者 order by要创建。

经常更新的最好不要创建，因为除了要修改原表还要去修改索引。



### Mysql LRU的优化

本质上是个LRU-K，但只有一个链表，链表的前半截是young节点，后半截是old节点，从链表的末尾选择淘汰，当加入链表时是加入到old的开头，当使用某个节点超过一定次数就加入到young节点的开头。

k取大了也不会，需要大量的数据访问才能把历史访问记录擦除。



### ？？？Mysql 乐观锁的实现

每个数据都附带一个版本，读的时候都会读这个版本号，如果对数据更新了就要将版本号加一，当事务提交的时候，就需要对版本号进行核查，检查记录当前版本是否与之前读取时的相同，只有相同才给予记录更新操作。

乐观就乐观在默认自己事务写的时候，其他事务没有干扰，如果发生冲突了就导致写失败，白写了，这就是代价。



### 为什么select *会导致查询效率低

1. 不需要的列会增加数据传输时间和网络开销： 

   ● 用SELECT * 数据库需要解析更多的对象、字段、权限、属性等相关内容，在 SQL 语句复杂，硬解析较多的情况下，会对数据库造成沉重的负担。 

   ● 增大网络开销，* 有时会误带上如log、IconMD5之类的无用且大文本字段，数据传输size会几何增涨。如果DB和应用程序不在同一台机器，这种开销非常明显。即使 MySQL 服务器和客户端是在同一台机器上，使用的协议还是 tcp，通信也是需要额外的时间。 

   ● 如果记录中包含超过 728 字节的数据，MySQL 将这些数据存储在一个额外的位置，并在记录中保存一个指向这些数据的指针。这意味着在读取记录时，MySQL 需要执行额外的一次 I/O 操作来获取超过 728 字节的数据。   

2. 失去MySQL优化器“覆盖索引”策略优化的可能性：

   ● SELECT * 杜绝了覆盖索引的可能性，而基于MySQL优化器的“覆盖索引”策略又是速度极快，效率极高，业界极为推荐的查询优化方式。 

   ● 如果用户使用select *，获取了不需要的数据，则首先通过非聚簇索引过滤数据，然后再通过聚集索引获取所有的列，这就多了一次b+树查询，速度必然会慢很多。 

   ● 由于辅助索引的数据比聚集索引少很多，很多情况下，通过辅助索引进行覆盖索引（通过索引就能获取用户需要的所有列），都不需要读磁盘，直接从内存取，而聚集索引很可能数据在磁盘（外存）中（取决于buffer pool的大小和命中率），这种情况下，一个是内存读，一个是磁盘读，速度差异就很显著了，几乎是数量级的差异。



### InnoDB和MyISAM的区别

- InnoDB 支持事务，MyISAM 不支持

- InnoDB 支持外键，而 MyISAM 不支持

- InnoDB是聚集索引，数据在索引的叶子节点，MyISAM是非聚集索引，索引和数据文件是分离的，索引保存的是数据文件的指针。
  - InnoDB的辅助索引叶子节点存有主键，是通过回表的形式查找数据；MyISAM辅助索引存的仍然是数据文件的指针，也就是说没有主索引和辅助索引这一概念。
- InnoDB 必须要有主键，MyISAM可以没有主键
- InnoDB支持表级锁、行级锁，默认为行级锁；而 MyISAM 仅支持表级锁

二者使用场景/如何选择？

- 支持事务的话只能选InnoDB
- 如果系统崩溃导致数据难以恢复，且成本高，不要选择MyISAM。因为InnoDB有事务的存在，必须支持undo redo等操作，具有故障恢复的能力
- 如果大部分表操作都是查询，选择MyISAM，有写又有读选InnoDB。因为写多了就可能冲突，得选支持事务的。



### mysql什么时候使用行锁？什么时候使用表锁？

InnoDB的行锁是通过索引上的索引项实现的，通过索引检索数据时，会使用行锁，否则一般使用表锁。



### mysql间隙锁的加锁范围如何确定

比如有一个索引，叶子节点的值分别时 12345556，然后一个selet数据包含了where value=5，这时候防止幻读，就不允许value=5的值的插入，就应该对第一个5的左边的间隙，最后一个5右边的间隙加锁，5之间的间隙加锁，所以范围是4-6，mysql里面的代码逻辑也很简单，从5往小的方向扫，找到第一个小于5的值作为左区间，然后往大于5的方向扫，找到第一个大于5的值为右区间，这个区间就是加锁范围。



### binlog

binlog日志的作用：

1、master的binlog日志传给follower，完成主从复制

2、数据库恢复，那和redo日志有什么区别吗

- binlog 会记录表所有更改操作，是具体的sql语句，包括更新删除数据，更改表结构等等，主要用于人工恢复数据，而 redo log 对于我们是不可见的，它是 InnoDB 用于保证crash-safe 能力的，也就是在事务提交后MySQL崩溃的话，可以保证事务的持久性，即事务提交后其更改是永久性的。一句话概括：binlog 是用作人工恢复数据，redolog 是 MySQL 自己使用，用于保证在数据库崩溃时的事务持久性。
- redo log 是 InnoDB 引擎特有的，binlog 是 MySQL 的 Server 层实现的,所有引擎都可以使用。



### 为什么MapReduce要先将中间数据写到本地磁盘

我觉得可能是为了系统的健壮性吧，写到磁盘上不会占用太多内存，也不会占用太多的网络带宽。设想一下，如果直接发送个Reducer，内存满了之后的数据要怎么处理呢？这个过程网络也有可能出现故障，又要怎么处理。



### 什么是火山模型

首先需要介绍数据库底层的执行是建立在一个物理执行树上，sql上层会根据查询计划生成这么一棵树。然后树的每个节点都是一个excutor，或者说是物理执行算子，然后火山模型最核心的逻辑就是每个excutor中都支持一个迭代器，可以叫做get_next，这个迭代器的功能就是从当前节点的子节点拔取一条数据，只要整棵树都支持这个迭代器，那么我们就可以从树的根节点拔取数据，然后一直递归到树的叶子节点，完成查询。当然有些物理执行算子它是不支持这种拔取一条数据的操作，比如说它需要返回全部数据，那么这个物理执行树在执行的过程中就必须在这个地方等待。





### Hash Join和Nestd Loop Join的区别

Nested Loop Join的算法实现主要是对两个表进行嵌套循环，通常选择比较小的那个表作为驱动表（因为被驱动表会访问多次，驱动表太大，就太多次了），具体一点就是驱动表挑一条数据，然后对被驱动表遍历。

Hash Join的算法实现则是对两个表中较小的那个表的key首先建立一个hash表，然后遍历较大的那个表，同样对数据进行hash，然后在建立好的hash表直接找hash值相同的所有值，再在里面找到匹配的值。

适用场景：

Nested Loop Join一般用于驱动表够小且被驱动表有一个选择性较好的索引的时候（遍历的时候快），但是嵌套循环是暴力循环在数据量大的时候就性能很差，所以在数据量小的时候进行使用。

Hash Join比较快，它快就快在一个表的一条数据在对另一个表进行遍历时，是直接在hash值相同的值里面找的，但这是基于建立好hash表的情况，在数据量大的时候建立hash表的开销和嵌套循环比少特别多，所以数据量大的时候性能提升特别明显。但是Hash Join只能用于两个值相等的情况，并且占用内存或者磁盘，需要维护一个哈希表。

具体选哪个，可能得看sql的优化器的代价计算。



### 什么是联合索引

聚簇索引的依据是根据主键这一个字段进行建立的，而联合索引是根据多个字段进行建立，多个字段的索引就可以支持判断条件更为复杂的sql语句。当然使用的时候，需要sql语句的判断条件能够和联合索引的字段支持最左匹配。



### 两阶段锁为什么可以保证冲突可串行化

两阶段锁的要求就是，事务对锁的使用分为两个阶段，第一个阶段是获取锁，只要释放了第一个锁，之后就不能再获取了。这样的话举一个简单的例子，假如事务A要读1数据，事务B要写1数据，之后事务A又要读1数据。如果使用了两阶段锁，事务A第二次读数据是拿不到锁的，因为它已经释放了1数据的锁，进入了shrink状态，这样就避免了读到不该读数据的情况。但是还是有级联回滚的问题。



### 请你介绍一下MapReduce的整个过程

首先MapReduce它的作用，就是将大文件分而治之吧，这个分不仅是任务的分小，而且还把任务分在了不同的服务器节点上，因为分在了不同服务器上就必须得额外考虑网络通讯的情况，可能会发生失败等。

整体来说，有两类节点，Master控制节点，Worker工作节点，worker也可以再分，分为mapper和reducer。

客户端是与master进行交互的，比如说向master提交一个任务，比如说是一个超大文件统计词频的任务。master的主要职责就是监控整个任务的执行状态，然后根据不同情况进行调度，刚开始它回把这个超大文件分成若干小块，然后通知worker首先进行mapper任务。

然后mapper在收到任务后，比如说就是统计词频，然后每个mapper会对这个小文件的所有单词进行一个hash，并把中间结果落盘。这里得说具体点，比如说1号worker对单词生成的hash值有567，那么它就会生成三个中间文件，15，16，17。二号worker同样会有hash值为567的情况，那么就生成25，26，27三个中间文件。等所有mapper工作结束后，master就会开始reducer任务。

每个reduer则是负责一种hash结果的中间文件，比如一个reducer负责5这个值，那么它就会去mapper节点上读像15，25的中间文件，然后将他们整合起来，再进行一个排序，最终输出这些中间文件的总词频情况。因为所有的reducer执行后，其实是多个输出文件，每个reducer一个，所以可能还得进行迭代，直到可以快速得到最终大文件的词频。



若干提问？

多个worker执行同一任务？命名的原子性。

backup任务怎么办？超时。通知另外的worker

什么时候排序？为了减轻reducer的负载，worker端先排序，reducer虽然还要排序，但是可以直接多路归并，否则reduce端还需要对每个中间文件进行排序后再多路归并。



其他拓展：

预处理，worker端提前reduce一次

根据不同hash值由不同的reduce结果。比如说分类。

mapper取文件时，就近取，因为GFS的存在，文件有多个副本。



### 数据库垂直分区和水平分区优缺点

垂直分区：一个表拆成两个表，存放不同的字段。（并不是列存）

- 好处，想读某些字段的时候不用读一整行，这种在有些列使用频度不高的情况下效果不错，并且可以根据业务分，比较清晰，比如这个业务我要这一列，那个业务主要用那一列。

- 缺点：没有解决单表数据过大的问题，seq scan还是很慢。

水平分区：

- 好处，解决单表数据过大的问题，从根本上解决大表的性能吧。
- 缺点：但由于同一个表的数据被分配在不同的数据库，需要额外进行数据操作的路由工作，因此大大提升了系统复杂度。



共有的缺点：事务处理麻烦，Join麻烦



### mysql和oracle有什么区别

整体说oracle是收费的，厉害很多。

oracle事务需要手动提交，mysql自动提交

oracle的锁好像大多数情况都是用行锁，而mysql在没走索引的时候用的是表锁，粒度大，并发性能不大好。

最大的区别，应该是底层的查询优化器，oracle在这方面厉害得多。



### 列存的特点

1、数据都是一列的数据存在一起，类型相同，压缩率高

2、适合分析型的查询，一般用于OLAP，因为OLAP的查询数据量很大，使用列存，可以不用读到不必要的数据，比如有些列是用不上的

3、但是修改数据代价较大，因为一行的数据被分散在不同地方，并且数据一般都有压缩，还要还原。



### 走索引一定会快吗

如果表中数据少的话，没必要用索引



### Join和Union的区别

UNION是两张表进行上下拼接，产生的两个记录集(字段要一样的)并在一起，成为一个新的记录集，分为UNION和UNION ALL（不去重）两种方法；

JOIN 是两张表进行左右连接，条件匹配的记录将合并产生一个记录集，有LEFT JOIN、RIGHT JOIN、INNER JOIN、OUTER JOIN（并集）等多种方法。



### Join，Left Join和Right Join的区别

join等价于inner join内连接抄，是返回两个表中都有的符合条件的行。

left join左连接，是返回左表中所有的行及右表中符合条件的行。

right join右连接，是返回右表中所有的行及左表中符合条件的行。



### mysql两阶段提交

协调器问所有节点是否prepare好了，收到所有回复后，再向所有节点提出commit请求。



### mysql为什么单表不要超过500w行

mysql的B+树一个节点是16k，一般三层B+树就可以存2kw的数据，数据太多B+树树高，太高则磁盘IO多，慢。



### mysql单表太大，怎么优化

- 字段优化：int用小的int，varchar尽量少用，null字段尽量少用
- 索引优化，建立有针对性的索引
- SQL语句尽量不要太复杂，尽量写走索引的SQL语句
- 分库分表
- 增大PageCache
- 读写分离：从库读，主库写



### 拓扑排序是为了解决什么问题的？

依赖性问题。判断是否成环。





## 分布式

### 6.824 分布式kv如何防止重复的写指令

客户端的每条指令标记指令号，然后服务器记录客户端号和指令号，来防止指令重复执行。



### 6.824和redis有啥区别

raft中使用的是共识算法，redis采用的主备复制；

raft只需要得到超过一半的响应即可，而redis需要得到所有备份的响应；

raft采用的同步复制，follower真正写完才返回（日志持久化），而redis采用的异步复制，先返回之后写。



### 6.824中CommitIndex和ApplyIndex的含义以及如何确定

CommitIndex：已提交的最大 Index, 代表过半节点已收到。

- leader的CommitIndex是权威的，代表得到超过半数节点确定的日志到哪了，follower的CommitIndex由AppendEntry来确定，如果某次AppendEntry成功了，则一起更新AppendEntry。

ApplyIndex：当前节点已应用的最大Index



### Follower读到旧的数据怎么办？（redis)

DDIA中具体分为三种场景：

- 读自己的写读不到
  - 方案1：读的内容假如是可能被修改的数据，则只能Leader读；否则，follower读。但有可能都会更改。
  - 方案2：可以外设一个监控器，监控Leader和follower的日志同步情况，记录Leader比follower快多少，如果超过一定阈值，就只能Leader读，这样即使读到旧的，也不会太旧。
  - 方案3：客户端维护数据更新的时间戳，读到的不够新，则换一个Follower。但可能受时间戳不可靠的影响。
- 读到了，第二次又读不到
  - 特定用户路由到特定服务器上，基于用户ID哈希。但服务器失效了还是需要重新路由到其他副本上。

- 写的顺序是123，读的顺序却不是。
  - 确保具有因果关系的写入都交由一个分区来完成，这个分区使用 Happened-Before 算法来追踪事件的因果关系（具体比较复杂，不展开）。





### 如何优化强一致性读的开销？(raft)

Trade off：较强的一致性以及较好的读性能。

如果想要得到较强的一致性，则只能是通过Leader读，并且Leader的合法性需要得到保证（通过广播，否则脑裂的错误Leader会出问题），但这样会增加Leader的负载，并且广播一轮也很慢。这里raft论文里面有两个优化：

- 针对每次读要广播的问题：

  Read Index：记录一个Read Index，每次读的时候进行广播，记录广播前的commit_Index为Read_index，广播确认合法性后，就记下来这个Read Index，下次读到小于这个Read Index，就直接读。

- 针对要经过Leader的问题：

  目标是用follower读，然后原则上follower的数据不一定可靠，所以follower需要去请求Leader，Leader在广播确认合法性后给follower一个Read Index，告诉这之前的数据都能读。这里其实还是经过了Leader，针对这个问题，可以采用租约机制，Leader在广播确认合法性后，设立一个租约时间，这个时间是小于candidate超时时间的，在租约之间内，Leader的合法性可以得到保证，这样在租约内就无需广播，follower在请求leader后同样获取这个租约，然后follower的租约时间减去RPC的最大时间，设立为follower的租约时间，这样就做到follower读。但这样又引入一个新问题：时钟不可靠问题。



条件放松一点呢？

可以外设一个监控器，监控Leader和follower的日志同步情况，记录master比replica快多少，如果超过一定阈值，就只能master读，这样即使读到旧的，也不会太旧。



raft——follower先请求leader，leader发一轮广播，确认自己的合法性，然后给follower一个read的index，之前的都可读。这样leader就需要一轮广播，leader可以采用租约机制来避免广播，每次heartbeat能够得到一个qurom就设立一个租约，时间是小于candidate超时时间的，但是这样需要服务器时间戳一致。

redis——确实是可能不一致，但是可以外设一个监控器，监控replica和master的日志同步情况，记录master比replica快多少，如果超过一定阈值，就只能master读。



### 时钟不可靠问题



### 多主节点复制



### 无主节点复制









---

## 计网

### TCP or UDP

相对于 UDP，TCP 实现了数据传输过程中的各种控制，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。在对可靠性要求较高的情况下，可以使用 TCP，即不考虑 UDP 的时候，都可以选择 TCP。比如付费、加密数据等等方向都需要依靠TCP。



UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务，随时都可以发送数据，处理简单且高效。
所以主要使用在以下场景：

- 包总量较小的通信（DNS、SNMP）
- 视频、音频等多媒体通信（即时通信）
- 广播通信



文本聊天是TCP，视频语音是UDP



### close_wait原因

服务端没正确调用close



### 三次握手，第三个包丢了会干嘛，直接发送数据会干嘛

主动端会超时重传第三个包，假如直接发数据，则包里面可以带ack，也不影响。**第三次握手可以发送数据**（`http请求报文`就是在TCP的`第三次握手`中携带在TCP的数据载荷部分）



### 网线断了会干嘛

超时重传



### https会被拦截吗，会被篡改吗

中间人无法篡改，因为第三个随机数用的公钥加密的，只有用私钥解析后才能拿到加密算法的方式。中间人没有私钥，所以无法知道加密算法的具体形式。



### traceroute原理

- 作用1：故意设置特殊的 TTL，来追踪去往⽬的地时沿途经过的路由器。  

  利⽤ IP 包的⽣存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的⼀种⽅法。  

- 作用2：故意设置禁止分⽚，从⽽确定路径的 MTU。ICMP会返回消息不可达和MTU的大小。 





### TCP粘包问题

什么是粘包：字面上就是数据被分块后，接收方没有正确还原，粘到缓冲区中了。

解决方案：

发送方粘包很大原因是Nagle算法，导致小的数据包一直不发送出去。解决方案：关闭Nagle算法。

接收方，从传输层的TCP解决不了，只能靠应用层读数据要读彻底，应用层的程序读，每次都循环读，直到读到没数据为止。



### 微信扫描登陆如何实现

首先电脑生成二维码，生成二维码的过程，是电脑的微信客户端去请求redis缓存服务器，然后redis缓存服务器会返回一个uuid，并且自己存下这个uuid，这个uuid是和二维码绑定的。

然后手机扫描二维码，扫描这个二维码的时候，手机会读到这个uuid，然后手机会带着这个uuid和自己的微信账号信息去访问redis服务器，redis因为之前有存uuid，所以就正确解析，然后把微信的账号信息传给电脑的微信客户端，然后电脑就成功登录。



### TCP几种定时器

重传计时器，坚持计时器（窗口等于0时用于发送探测报文），保活计时器（防止连接之间长时间的空闲，通常在两个小时），TimeWait计时器



### 由于有TimeWait存在，大量短连接怎么处理

如果短时间内来了大量短连接，则服务端的socket可能都处在TimeWait状态导致服务器无法进行新的连接，该如何处理：

客户端方面，短连接改成长连接，但是长连接太多会影响服务器的性能。

1、打开tcp的reuse和times_stamp功能，让内核可以复用Time_wait超过一秒的socket

2、程序中设置close的行为，如果onoff参数非0，linger参数为0，close时会发送RST标志给客户端，则直接跳过四次挥手，也跳过timewait

3、设置timewait的数量，但是治标不治本



### Close_wait状态什么时候出现

被动方第二个挥手包发送后，变成close_wait。如果程序中出现了大量的端口是close_wait状态，说明程序可能没有合理地调用close系统调用。



### Get、Put、Post相关/Http的常见类型

有长度限制吗？协议上无，有限制的话一般是浏览器或者服务器做了特定的限制。

**Get VS Post：**

GET是获取服务器上的数据，而POST是去给服务器提交数据，所以Get是幂等的，安全的，不会修改服务器的数据，同样的Get一般能获得同样的数据，**而Post用于修改服务器上的数据，有副作用，非幂等，不一定安全。**

具体点，GET产生一个TCP数据包；**POST产生两个TCP数据包**。对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。



**Put VS Post**

最主要的区别是Put是幂等的

使用PUT时，必须明确知道要操作的对象，如果对象不存在，创建对象；如果对象存在，则全部替换目标对象

同样POST既可以创建对象，也可以修改对象，但用POST创建对象时，之前并不知道要操作的对象，由HTTP服务器为新创建的对象生成一个唯一的URI；使用POST修改已存在的对象时，一般只是修改目标对象的部分内容。

PUT是“idempotent”（幂等），意味着相同的PUT请求不管执行多少次，结果都是一样的。但POST则不是。就类似于"x=1"这条语句是幂等的，因为无论执行多少次，变量x的值都是１；但"x++"就不是幂等的，因为每执行一次，变量x的值都不一样。



### cookie和session的区别

这两个技术主要用于Http，因为Http是无状态的，当面对比如说用户登录，购物车等一些有状态的、个性化的场景时，普通的http就会重复验证用户信息，效率比较低，所以提出了这两个概念。

- cookie主要运行在客户端，是有服务器发送给它的，而session是运行在服务端的，由服务端在收到请求时自己创建
- 客户端浏览器的cookie一般由个数和大小的限制，而session没有，但是session过多会占用服务器资源
- 有效期不同，Cookie可设置为长时间保持，比如默认登录功能功能，Session一般有效时间较短，客户端关闭或者Session超时都会失效。
- 隐私策略不同，Cookie存储在客户端，信息容易被窃取;Session存储在服务端，相对安全一些。
- session技术是建立在cookie之上的，如果关闭了cookie，那每次访问都需要建立一个新的session，会影响性能。



session太多了怎么办？

- 分布式，主备复制
- 一致性hash，负载均衡
- 统一存放在redis中



### 如果交换机中没有找到ip和mac的映射怎么办呢

会发送大量重复的arp包，然后利用ICMP协议通知服务器用户不可达。理论上内网里面ip和mac都有缓存，arp都是特别少的，多了就出问题了。可能是：某个机器arp响应的mac和它自己真实的mac不一样。



### 负载均衡的方式

- Http重定向，但是需要浏览器请求两次服务器才能完成。并且重定向服务器很容易编程瓶颈，因为一次重定向返回的过程，也是一次标准HTTP请求，如果集群内有10台机器，那HTTP重定向服务器的流量将是应用服务器的10倍。
- DNS（应用层），1选择就近的DNS服务器，2DNS服务器对一个URL有多个ip地址，选一个负载轻的或者是近的。
- 负载均衡服务器，监控所有服务器的状态，根据负载均衡算法分配一个负载轻的。
  - 运行在网络层，负载均衡服务器和最终的服务器ip地址不一样，修改包的ip地址，再发送给最终的服务器。
  - 运行在数据链路层，维护负载均衡服务器和最终的服务器地址统一，修改mac地址进行分发。

总结：本质上就是传到一个服务器上后，进行更改目标地址，可以按照不同层的协议进行更改。



### TCP和UDP可以共用一个端口号吗

当然可以,因为TCP和UDP是不同的协议,IP报文到了后会根据传输协议的类型来决定由内核中的哪一个软件模块处理。两者是独立的。

端口对UDP是必须的吗？是。报文头部里面有。



### 网络层和传输层有什么区别

- 网络层是为**主机之间**提供逻辑通信，其主要任务是：通过路由选择算法，为报文通过通信子网选择最适当的路径。像很多路由器最高层就只到传输层，因为他们不必向上层应用提高服务，选择好主机就好了。

- 传输层为**应用进程之间**提供**端到端**的逻辑通信。在选择好主机后，还要选择端口，保证端到端的服务，使高层用户看到的像是在两个应用之间进行通信。

  

### ！！！TCP怎么保证可靠（有序不重不漏不错）传输

1. 序列号
   TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
   序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。
2. **确认应答**
   基本原理是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
3. **校验和**
   TCP 将保持它首部和数据的检验和。
   这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. **流量控制**
   TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
5. **拥塞控制**
   当网络拥塞时，减少数据的发送，防止包的丢失
6. 超时重传
   当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。





### HTTPS包被篡改了怎么办

一般叫做**中间人攻击**，如何进行攻击：一般都是在**建立 SSL 连接时**，拦截客户端的请求，**利用中间人获取到非对称加密的公钥、对称加密的密钥。**

怎么办？利用第三方提供的**数字证书机制**来验证。（可信任的第三方机构为双方提供数字证书以及一个公钥，之后可以用这个公钥来解析对方发的数字证书，如果验证成功则说明信息没有被篡改，只要第三方机构是可信的，那么就是可靠的。）





### 从中国到美国的网络为什么慢？

1、首先是距离远，中继节点多

2、其次，可能经过一些关键路由器，大型网络中关键路由器的路由表条目特别多，可能几千万条，遍历就很慢（需要MPLS来改进）

补充：MPLS是利用标记进行数据转发的，在报文中，mac层和ip层中间再加一个MPLS头部设置标记，根据MPLS的标记直接转发，而不是查找路由表（完全遍历），将路由转发变成类似交换转发的模型（查mac表，匹配则转发），生成一个标签表，查找时匹配则转发。利用一个中心LSR和边缘LER的网络结构。



### MTU和MSS的区别

MTU ：⼀个⽹络包的最⼤⻓度，以太⽹中⼀般为 1500 字节。（IP层，包含IP头部和TCP头部）
MSS ：除去 IP 和 TCP 头部之后，⼀个⽹络包所能容纳的 TCP 数据的最⼤⻓度。  （TCP层，去除TCP头部，就单指数据包大小）



### 长连接，短连接不一致的时候会发生什么？

两种情况



---

## OS

### ！！！进程、线程、协程的关系和区别？

先答：进程是操作系统资源分配的基本单元，线程是CPU调度的基本单位。然后围绕资源分配（堆栈空间，虚拟地址）展开，共享资源 -> 通信，切换开销等。



最主要的区别是协程不被内核调度，而是由用户态的程序调度，它是在用户态下实现的。一个线程可以跑多个协程，在线程切换频繁的场景(IO密集型计算)中，使用协程可以减少切换开销。因为线程的开销是固定的，在线程切换频繁的场景，想要减少切换开销，唯一的办法就是减少线程数量，但是程序又需要多任务并发执行的逻辑，这就抽象出协程的概念，一个线程里跑多个协程，由自己调度，通过减少线程的总数量来减少线程切换开销。

（别说到并发量，应该说并行!!!）



场景：

多线程：**IO密集型/或者需要频繁进行通信多任务**，IO密集型因为经常有IO中断，任务会被阻塞，这时候最好就把阻塞的任务切走，因为多线程的切换开销小一点，所以用多线程。

​		缺陷：稳定性较差，隔离性较差，需要用锁之类。

多进程：**计算密集型/对资源的管理和保护要求高**，计算密集型就是任务主要是需要CPU参与计算，而IO中断会少一点。这时候就用多进程，因为很少发生中断出现阻塞，即使进程开销大一点，受的影响也会相对较小，同时多进程各个进程的地址空间都是独立的，隔离性更好，程序也相对稳定。

​		缺陷：多个进程之间通信成本高，切换开销大。

多协程：**超多任务量。**

​		缺陷：一般没必要使用。（**在没有达到CPU核心数的任务量时，用户态的开销是多余的**）



> > 多线程请求返回是无序的，那个线程有数据返回就处理那个线程，而协程返回的数据是有序的。
>
> 缺陷：单线程执行，处理密集CPU和[本地磁盘](https://www.zhihu.com/search?q=本地磁盘&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2868711843})IO的时候，性能较低。处理网络I/O性能还是比较高。



### 进程线程切换具体要做些啥

进程：页表切换（会导致TLB失效），内核栈，寄存器

线程：内核栈，寄存器



### Linux系统CPU占用100%原因分析

除了确实是计算密集型应用（正则表达式搜索，加密解密）之外，通常原因都是出现了死循环。



### 内核态和用户态如何做信息交互

系统调用的过程：虚拟地址的转换，用户态寄存器信息存放于PCB中，切换页表寄存器内容等。

还提供文件系统的一些文件可供修改内核参数。



### 函数调用时栈是如何变化的

函数栈存放的东西主要有三个：各个局部变量、寄存器的值、上一层函数的栈帧地址。

在函数调用时，就将上层函数的栈帧地址，局部变量和一些寄存器的值压栈，然后进入新的函数栈帧中。



这个函数栈是存放在进程的栈区的。



### 小端存储

小小小，低字节在低地址。



### CPU亲和性

CPU 亲和性就是进程要在某个给定的 CPU 上尽量长时间地运行而不被迁移到其他处理器的倾向性，更好利用缓存。

如何设置

```bash
taskset -c 0,1 vim # 此处以vim程序为例，操作指定了vim启动时可用的cpu为核0,1；
```



### cpu飙升如何排查

top指令全局

pstree看进程结构

ps aux



pidstat



ps和top的区别？

ps：查看进程的瞬间信息，主要是查看进程的。aux所有用户(a)，或者当前用户(u)

top：可以实时查看进程信息，还有CPU和内存的信息，主要是看CPU和内存情况吧。使用 `top -p PID` 可以查看指定的服务占用资源情况。



### 红黑树为什么是logn的？

因为红黑树是二叉树，并且基本上是平衡的，所以树的高度为logn，所以查找删除也等于logn。大概是这样，严谨一点需要数学归纳法。



### read函数的返回值

1、返回读到的字节数

2、返回0，读到EOF

3、返回-1，出错（如果是非阻塞IO，errno=EAGAIN，EwouldBlock表示无数据可读了，如果是EINTR表示被系统中断打断了）



### epoll_wait参数问题

第一个参数是epfd的参数

第二个参数是event，返回一个就绪事件的链表

第三个参数表示epoll最多有多少个事件

第四个参数表示超时时间，指定超时值为-1会导致epoll_wait（）无限期阻塞，而指定的超时时间等于零导致epoll_wait（）立即返回，即使没有可用事件，并且很占cpu。



### 在事件比较少的时候，阻塞IO（BIO）和非阻塞IO（NIO）哪个好？（五种IO模型，性能排个序）

- BIO：一个线程一个事件
- NIO：一个线程多个事件，线程一般开得比较少
- AIO：异步IO，Proactor模式

事件比较少时，BIO更好，因为一个线程可以专注于一个事件。一般来说，NIO开的线程不会太多，因为一个线程可以处理多个事件，所以NIO可能多个事件在同一个线程上，效率不如BIO。但是BIO比较吃服务器资源。



### EpollOneshot

注册事件时，加上这个标志，可以让某次循环中epoll_wait唤醒该事件fd后，就会从注册中删除该fd,也就是说以后不会epollfd的表格中将不会再有这个fd,也就不会出现多个线程同时处理一个fd的情况。

使用：

- listenfd不需要注册EpollOneshot，因为就一个主线程监听。
- 工作线程，如果当前工作处理完，对事件重新注册需要额外加上EpollOneshot，因为注册了EpollOneshot的事件在被唤醒后会从epoll中删除。



### epoll线程安全吗

安全；Epoll内部的就绪队列用的自旋锁，红黑树用的互斥锁。



### Linux栈的大小为8M或10M

### fork()内核发生了什么

陷入内核态，内核创建一个子进程，但是这个子进程并没有自己的内存，和父进程共享代码区和变量区，当子进程修改这些区时，会发生缺页中断，然后内核会分配一个页，分配内存，然后子进程相关的页的指针就指向新分配的。



### 僵尸进程是什么？怎么处理？孤儿进程是什么

僵尸进程是当子进程比父进程先结束，而父进程又没有回收子进程，释放子进程占用的资源，此时子进程将成为一个僵尸进程。

怎么处理：kill，采用ps处理可以看到哪些是僵尸进程，僵尸进程有defunct标记

怎么避免：父进程waitpid()

孤儿进程：父进程先于子进程结束 



### 信号量的实现

我运行了2个线程A和B，但是我希望B线程在A线程之前执行，那么我们就可以用信号量来处理.

```c++
class Semaphore
{
public:
    Semaphore(long count = 0) : count(count) {}
    //V操作，唤醒
    void signal()
    {
        unique_lock<mutex> unique(mt);
        ++count;
        if (count <= 0)
            cond.notify_one();
    }
    //P操作，阻塞
    void wait()
    {
        unique_lock<mutex> unique(mt);
        --count;
        if (count < 0)
            cond.wait(unique);
    }
    
private:
    mutex mt;
    condition_variable cond;
    long count;
};


Semaphore sem(0);
void funA()
{
    sem.wait();
    //do something
    cout << "funA" << endl;
}
 
void funB()
{
    this_thread::sleep_for(chrono::seconds(1));
    //do something
    cout << "funB" << endl;
    sem.signal();

```





### 怎么判断程序是否发生了死锁，具体原因是啥，应该怎么debug解决？怎么避免死锁？

- 怎么判断程序是否发生了死锁：
  - 用pstack+进程id来看程序的堆栈信息，看看各个线程是否有lock_wait状态，通常跑一次可能还不能说明问题，如果多次运行程序都这样，那么大概率死锁。
  - 使用gdb，可以info threads查看所有线程，然后用thread+线程号进入具体线程，再用bt指令看具体堆栈，看在哪一行出现等锁的情况。
  - 开个后台线程，构建各个线程的依赖关系，比如线程A在等B，则A指向B形成一条边，最后看是否成环。成环即死锁。
- 具体原因：
  - 资源互抢，两个线程，一个拿着不放，一个又一直想要
  - return前忘记解锁
  - 嵌套加锁，函数加锁了，调用另外一个函数，这个函数也想要加锁
- 如何debug，如何定位：
  - 加锁解锁的地方，打日志，看加锁解锁是否成对存在，不同位置打不同日志，就可以看出来。
  - gdb，可以具体看在哪一行。
- 怎么避免：
  - 其实从代码的角度来看，锁的使用粒度小一点，作用域短一点，这样就不容易死锁。但是其实我觉得如果写代码，刚开始写最好还是粒度大一点，因为粒度小了可能不会死锁，但是有时候线程不安全，这个又被发现，程序就可能出现一些不可思议的结果，那时候去定位就特别麻烦。
  - 然后就是对于锁的使用，最好使用好自动释放资源的锁，比如unique_lock，因为经常就是加锁了忘记解锁了导致死锁。
  - 避免嵌套加锁



### Linux三剑客——grep，sed，awk



###  gdb调试器的简单使用调试coredump文件

编译的时候要添加-g选项

或者cmake -DCMAKE_BUILD_TYPE=Debug Path 

命令：gdb+可执行文件+core文件，然后bt指令

线上的程序没有加-g，bt出来全部是问号怎么办？

对程序提取符号表

```bash
eu-strip 程序 -f testdebug.sym # 符号表存在testdebug.sym
然后在gdb中敲
symbol-file testdebug.sym
```





### 内存映射

 ```c++
void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
 ```

addr：内存映射起始地址，通常设为NULL，由系统分配

length：共享内存映射的大小，一般是磁盘文件的长度，单位字节

port：共享内存访问权限，PROT_READ，PROT_WRITE，PROT_READ|PROT_WRITE,

flags：标注共享属性：MPA_FIXED（add具体指定后，禁止创建）,MAP_PRIVATE(只读映射),MAP_SHARED（读写自由），用于创建共享映射区的那个文件的文件描述符

offset：偏移位置，需要4k的整数倍

返回值成功的话显示映射区的首地址。

返回值失败返回 MAP_FAILED

mmap，支持匿名映射（flag中增加 MAP_ANONYMOUS，通常用于父子进程通信）和文件映射（和open配合使用）



 ### linux查看监听端口命令 

netstat -lpt



### 进程间通信哪个最快

共享内存最快。共享内存包括：

shmget（开辟一块**真实的物理内存**，每个进程开辟空间映射，快，小），shmat，shmctl，shmdt

mmap（在**磁盘上**建立一个文件，每个进程存储器里面，单独开辟一个空间来进行映射，慢，大，操作简单好用）



第二快感觉是管道。



### linux的段页式管理会产生内存碎片吗

不会。0-4GB这个段应该是逻辑上的虚拟地址，在真实的内存并不是连续的，里面的各个地址本质上是以页式存储。分出这个段就是为了方便管理内存并且起到隔离的作用。



---

## WebServer

### 优化角度/瓶颈

我觉得很大的一个优化角度是线程池的大小，我项目里面的大小是人工设定的，不能动态调整，假如想修改线程池的大小必须修改源码去修改，线程开多了占用系统资源，开少了又限制并发量，假如能够根据CPU核心的数量和服务器状态动态调整线程数量就好了。

怎么看服务器状态呢？netstat命令，可以看网络状态，比如所有连线的端口和端口的对应TCP连接状态；或者是top指令可以看CPU负载，各个线程占用CPU的资源程度等。



**优化角度汇总：**

1、硬件：cpu核心数，内存有多大，网络带宽最大多少（iftop工具可以看占用情况）

2、软件方面

配置优化：线程池大小、TCP发送缓冲区、timewait_reuse功能、epoll_wait超时时间、文件描述符数量。

- 一个是线程池的大小问题，多了切换开销大，少了任务又处理来不及。

- 服务端的每个TCP连接的接受缓冲区（最大8M）和发送缓冲区（最大16M）的大小设置，用webbench测的，不明显，它那个模拟包数据量可能很小。

- 整个系统支持最大的文件描述符数量好像是一千万左右，单进程最大文件描述符最大是一百万左右，如果单进程的并发连接最多就支持一百万，想突破一百万就必须得多进程。其实我做的测试，也没有达到百万级别，但是刚开始写出来的时候并没有意识到这个问题，导致我的长连接数量有限，后面改了之后会有提升，但是长连接数量一上来，CPU占用程度就特别大，特别卡。

  当然前面说的是长连接，但很多时候连接都是短连接，短连接它不会长时间占用文件描述符，它比较不关心最大并发数量，可能关心的是平均响应时间，这个方面：

  - 我印象比较深的是timewait_reuse功能，没有打开这个的话，短连接连接多的时候，很多端口都会出现timewait状态，因为服务器在处理完短连接后会主动关闭连接，打开timewait_reuse和tcp_timestamp功能就可以复用超过一段时间的timewait状态的端口，这样就能一定程度上缓解timewait带来的负面作用。
- ~~还有就是epollwait超时时间的设置，我发现这个参数不能太大也不能太小，最完美情况下是多少我可能不清楚，但是太小了的话，我发现很占cpu资源，应该就是一直反复使用系统调用，内核用户切来切去，但是太大了的话，在并发度高的时候，响应就慢了，因为等太久了。可能得慢慢调吧~~
  
  - time_out除非是0，否则不会影响epoll的开销。因为有事件来时，epoll一个循环就会返回并不会达到超时时间。除非设置得超级短。



可以继续做的点：

1、缓存优化？LRUCache。

- Cache页的设计：页号，计数器。
- 维护文件的页表。

2、Reactor之间的负载均衡。本身用的是RoundRobin。选择连接数量最少的。维护一个每个Reactor中连接数量的数组。

3、再扯远一点就是分布式了




### LT模式也有优点

在socket集合小的时候，请求少的时候，由于LT醒的更频繁, 可能**时效性更好些.** 



### 在事件少的情况下，阻塞和非阻塞哪个更快

阻塞吧。因为非阻塞能够成功返回必须要事件已经发生了才会起到作用，不然就返回-1，那么这时候用非阻塞的模式频繁地去询问事件是否完成，很大程度是浪费资源。所以阻塞的效率更高。



### 如何实现一个线程池

线程池主要维护一个东西，任务队列。我在实现时，是参照生产者消费者模型去实现的，因为各个线程空闲时都要去任务队列取任务，所以还需要维护一个条件变量和锁保证并发的安全性。然后每个线程是在线程池构造时就生成好了，逻辑也很简单，就是一个死循环，循环里面的内容就是一直判断，任务队列里有无任务，有的话就取一个进行执行，同时循环里还要判断线程池是否关闭，关闭了就执行完任务后退出。



### 线程池大小如何确定

最简单的经验就是看cpu核心数。

高阶一点：

（cpu_time + io_time） / cpu_time * NumberOfCore

IO时间越多，说明线程等待的时间就越长，这个时间其实可以理解CPU是空闲的，这个时候就多分配一些线程数量。

代码里面除了读磁盘的html文件被视为io操作，其他都认为是cpu操作。然后利用std::chrono::system_clock::now()函数来统计时间确定



### 为什么要用定时器

最主要的原因是处理非活跃连接，比如一个短连接来了，但迟迟不进行读写数据，占用描述符，所以就用定时器让他一定时间后滚蛋，减轻服务器压力。除了这个原因之外，还可以方便其他定时事件的处理，比如长连接时间到了为了不断开我就重新注册它的超时时间。

代码逻辑：定时器每个时间点到了，就会通过管道向主线程发送alarm信号，主线程收到信号后，便对所有的定时器开始检验，检测是否有超时回调函数需要执行。



### 压力测试相关

怎么进行压测的？我是使用Webbench对服务器进行压力测试，webbench可以模拟多少个客户端在多长时间内对server进行并发访问。

测试遇到什么问题？

1. 在并发量高的时候有些连接无法正常断开，直接导致我的程序崩了。

   排查：

   起初我以为是内存泄漏问题，我重构了整个项目的指针，有些地方用智能指针，很大改善，log中error明显减少，但仍有问题，还是无法断开。

   *然后我又纠结在一个socket有多个事件来临时，能不能同时处理，就比如说一个socket同时可读和可写，这里的逻辑是if加上else if ，还是if 加上另一个if，结果发现是第一种能使我代码并发量更高，后来分析原因感觉是，当你把可读的事件处理完之后，假如想立即去处理可写事件，因为可读事件的处理花费了一定时间，这时候socket不一定可写了，可能连接已经断开了，所以应该是if加上else if的组合，也就是说一次epollwait中，对每个socket只处理一类事件。*

   最后发现还是不能断开，后来发现是对可读事件的回调函数写错了，当不可读的时候，read返回的是-1，我没有对erro的类型做出判断，最后出了问题。

2. 长连接只能达到1000个，起初我的epoll管理的数组的大小问题，改完之后没有反应。然后看top指令看cpu负荷，好像也不大，最后用了lsof看了文件描述符的占用情况，发现只能用到1024，这才发现问题，后面修改了一下单个进程最大文件描述符个数的那个配置文件，解决问题，最终提高了长连接的最大数量。



### 服务端大数据包怎么发，一个send解决？

计算出要发多少个字节，然后维护一个变量表示剩下多少字节需要发送，然后while循环里面套send函数（ET模式），send函数的返回值是发送成功的字节数，返回成功后剩下的字节数就减少，直到剩余字节为0。

http2.0还支持数据的压缩。



### 正则的使用

std::regex 和 std::smatch





### 多线程的信号问题

对于内核，信号的发送是发送到某一个进程的，它不知道进程内的多线程情况，因此在多线程下使用信号，如果不提前处理也就是说屏蔽，那么每一个线程都会收到信号，线程可以使用信号掩码屏蔽某些信号。

因为我项目里用的是线程池，对每个线程池一一去屏蔽有点麻烦，所以比较好的方式是单独开一个线程去处理信号，然后主线程在线程池创建之前屏蔽信号，这样线程池创建的线程就会继承信号的屏蔽。屏蔽的api：pthread_sigmask



### BackLog参数是全连接队列的大小



### 线程越多越好吗？

不是，最好和CPU核心数量一致。否则也会涉及到线程的切换，如果太多了，切换的开销会奇大无比。



### 为什么要用边缘触发？

说一下和水平触发的区别，然后说一下优势。

- 优势在于：因为Epoll一个socket在有事件来临时只会通知一次，因为要求用户态的程序必须一次性处理完。这样在高并发，大流量的情况，**会比LT模式下少很多epoll的系统调用，因此效率比较高**。频繁的系统调用，就会频繁地从用户态切换到内核态。

  

### 为什么要用Epoll？

说一下和select和poll的区别，然后说一下优势。



### 发送一个HTTP请求，服务器生成响应，怎么判断这个响应是否完整然后浏览器进行渲染？

返回的HTTP报文中含有content-lenth字段



### 了解网络编程的API吗？说一下建立连接的整体流程。三次握手第一个包是对应哪个API，第二个包第三个包等。

socket一个文件描述符，内核里面发生了什么？

- 首先说说系统调用的执行过程，就是用户态执行这个系统调用时，会产生一个叫做ECALL的硬件中断，然后内核会感受到这个中断，并切换到内核态，这个ECALL是带了一个数字，然后内核就根据这个数字去system call表去查，然后执行对应系统调用的代码。

  至于内核发生了什么，这里我可能只能说个大概。

  第一步就是先创建socket的结构体，这个结构体里面的内容就定义了协议族（AF_INET、AF_INET6），ipv4或者ipv6，然后又定义了套接字类型，流类型还是数据包类型，表示是TCP还是UDP，不同协议族不同套接字类型好像是放在不同类型的链表上进行空间管理。

  第二步就是在创建好结构体之后，然后调用文件系统的接口，申请空闲的文件描述符，然后和结构体进行关联。

bind的时候内核发生了什么？

- socket系统调用只规定了地址族和IP协议类型，比如说走TCP（SOCK_STREAM）还是UDP，然后bind系统调用就需要指定本地的ip地址和端口号。

  内核会做的第一件事，就是检查参数地址是否正确，这个时候会查一下页表，检查参数地址是否合法，不合法就直接杀死进程，说简单点就是内存越界。

  第二件事就是，判断IP地址是否符合格式，并且判断端口号是否已经被占用了，并且如果端口号<1024还得判断是否有权限，因为<1024的很多是一些特定功能的端口，只能root用户使用。

  第三件事，就是创建一个结构体，这个结构体就是socket和ip和端口一个绑定的信息，然后内核会将端口号进行一个hash，然后放到对应哈希表链表的桶里面，大概是这样。

listen时内核发生了什么？说backup参数是干嘛的。过大过小会发生什么？

- 第一步，先根据文件描述符，找到对应的socket结构体。

  第二步把结构体的状态设置成listen，并设置backlog的队列大小。

  



---

## 场景

### 问多个服务节点，如何让客户端访问它们

（答：用一台负载均衡服务器）。面试官好像希望用DNS来实现，实现就近访问。



### 高并发内存读写——双buffer

主要针对的是一写多读的情况，由于多个线程对同一变量的读不需要同步，因而一写多读和一写一读并无本质区别。

思想：由于是一写多读，写线程只向备份变量中写入，而所有的读线程只需要访问主变量本身即可。当写进程对备份变量的写操作完成后，会触发主变量指针和备份变量指针的互换操作，即指针切换，从而将原变量和备份变量的身份进行互换，达到数据更新的目的。



[UNIX(多线程)：28---双buffer “无锁” 设计_wx5f5ed5b01c9a8的技术博客_51CTO博客](https://blog.51cto.com/u_14934686/5813464)



### 海量数据题

hash、位图

- 100亿个整型数据（面试官提示，100亿不重要，反正很多），乱序，100M内存，无外存（也就是不能写入到文件），求中位数

  我提出用HashMap，面试官补充说没有硬盘

  我提出用BitMap，面试官说100亿个你装不下的

  他提示我，怎么用多轮处理，找到它大概的范围，我没get到

  最后他又提示，可以二分，整型上限40亿，可以统计0~20亿，和20亿到40亿的个数，然后每次排除掉一半，但是太慢，怎么继续优化

  我说N分，他说那N是多少？划分出来的区间，最小能是多少？

  我说一个字节对应一个区间，但是很快发现最坏情况下，一个字节装不下

  挖到这里没有继续往下挖了，面试官说反正到了这一步就是怎么分配单个区间大小的问题

- 海量数据topk：

  1. 维护一个k大的堆，然后遍历

  2. 排序：内存足直接排，内存不足外部归并排序
  3. hash：文件分块后，找出每个块最大的元素（排序，堆，遍历（临时hash表维护）），然后再次分块，统计

  topK，分别写出范围小、范围大、范围超大（说思路）的情况。

  答：分别是计数（桶排序）、快选、分治

  

中位数：按顺序排列的一组数据中**居于中间位置**的数

**桶排序** ：工作的原理是将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）

场景题：100万个选手，每个选手有对应的id和分数，要求参赛选手可查询分数前100的名单，和自己的排名，ps：排名可能随时更新，可能一天是10万级的更新，因此对应的前100名单和选手排名也要更新。

根据分数分段用了桶排，对用户id使用红黑树查分数，获得分数就知道在哪个桶了  （推算出自己的排名） 